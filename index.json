[{"uri":"/6-invalidatecachecloudfront/6.1-addstagepipeline/","title":"Add Stage in CodePipeline","tags":[],"description":"","content":" Access the CodePipeline console, select Pipeline, click on react-deploy-pipeline, then choose Edit. Scroll down to the bottom and click Add stage. Enter the name for the stage as InvalidateCloudfront. Then click Add stage. Select Add action group, Next, name it as Invalidation. Choose the Action provider as CodeBuild. We will use CodeBuild to execute a command to call the CloudFront API for invalidation. For the region, select the same as the region of CodePipeline. Select Input artifact as SourceArtif. Click Create project. The interface for Create build project appears. Name the project workshop-01-invalidation. For the service role, select New service. With this service, your first build will fail because it doesn\u0026rsquo;t have access to CloudFront to create invalidations. So attach the CloudFrontFullAccess policy to it. Next, in the buildspec section, add the configuration directly as follows: version: 0.2 phases: build: commands: # Invalidate - aws cloudfront create-invalidation --distribution-id E350YLUNXCX5JQ --paths \u0026#34;/*\u0026#34; Where E350YLUNXCX5JQ is the distribution id of CloudFront we created in step 5.3\nKeep the remaining configurations as default. Then press Continue to Codepipeline. Back in the Edit action interface, we see the notification that our project has been successfully created. Choose single build and click Create Action. The action has been created, scroll up and click Save. "},{"uri":"/3-developmentenvironment/3.1-createcloud9/","title":"Create Cloud9","tags":[],"description":"","content":" TOn the homepage of the Cloud9 service, click Create environment. In the Details section Enter Name as react-app-workshop. Choose Environment type as New EC2 instance. In the New EC2 instance section: Select instance type t3.small For Platform choose Amazon linux 2 Leave Timeout as default (30 minutes before hibernation due to inactivity). Network section: Under Network settings, choose AWS Systems Manager (SSM) for Connection. For VPC Setting, select workshop-01-vpc and private subnet. Click Create Cloud9 Check for successful creation: After approximately 10-30 minutes, the Cloud9 environment should be successfully created. Access Cloud9: Click on Open Cloud9 IDE to access its interface, which resembles other IDE software on the market. You can perform a ping to 8.8.8.8 to check internet connectivity. However, all packets sent are lost, indicating that our development environment cannot access the internet.\nAs mentioned earlier, we won\u0026rsquo;t be able to install necessary dependencies for our project because of this. Therefore, in the next step, we need to enable internet access for our development environment by creating a NAT gateway.\n"},{"uri":"/4-createcicd/4.1-createcodepipeline/","title":"Create CodePipeline","tags":[],"description":"","content":" Accessing AWS CodePipeline: Select Pipeline. Choose Create pipeline. Within the CodePipeline creation interface: Enter react-deploy-pipeline into the Pipeline name field. For Pipeline type, in this lab, we opt for V1. Regarding Excution mode, we select Superseded Superseded refers to the scenario where a new execution is triggered (such as when a change is introduced to the source code), it initiates and proceeds with deployment steps. During this process, if another execution is running concurrently, the deployment process may automatically halt and replace the older execution with the newer one.\nFor Service role, choose New service role. Additionally, check the box Allow AWS CodePipeline to create a service role so it can be used with this new pipeline In the Advanced Settings, designate Artifact store as Default location to store artifacts in the same region as CodePipeline. For encryption of objects stored on S3, opt to utilize Default AWS Managed Key as the Encryption key Select Next For the Add source stage: Choose AWS CodeCommit as the Source provider. Select workshop-01-react as the Repository name. Choose master for the Branch name. Check the box to utilize Amazon CloudWatch Events for automatically triggering the pipeline upon changes in the repository. Regarding the Output artifact format, opt for CodePipeline default. Our artifact will be the cloned source code compressed into a zip file but excluding git metadata. Select Next Under Build provider, choose AWS CodeBuild. Ensure the Region aligns with our project\u0026rsquo;s, i.e., N. Virginia. As we haven\u0026rsquo;t yet created a CodeBuild project, select Create project. This prompts a new tab for configuring the CodeBuild project.\nEnter workshop-01-react in the Project Name field. For configuring the environment (EC2) for CodeBuild to execute the project build, select as illustrated below: Proceed with selecting New service role. In the BuildSpec section, for the scope of this lab, we will directly add configurations to the Build Commands. In practice, a buildspec.yml file would typically be added to the root repository of the project. This facilitates developers to easily modify the build process without needing access to the AWS CodeBuild console. However, it\u0026rsquo;s not guaranteed they\u0026rsquo;d have such access\nThe added configuration appears as follows:\nversion: 0.2 phases: install: runtime-versions: nodejs: 18 commands: # install npm - npm install build: commands: # run build script - npm run build artifacts: # include all files required to run the application files: - \u0026#39;**/*\u0026#39; base-directory: build A quick glance shows that the configuration outlines the process of building our source code on an environment with Node.js version 18 installed, executing shell commands, and outputting artifacts from the build directory.\nFor syntax and further examples of BuildSpec configurations, refer to here.\nFor logging, select CloudWatch log to view the build logs of CodeBuild. Choose Continue to CodePipeline Upon returning to the CodePipeline creation interface, we notice that the project name has been automatically added to the newly created CodeBuild project, and a notification of successful CodeBuild project creation. For Build type, select Trigger single build, meaning each time you initiate a build, CodeBuild generates a separate build container to compile your source code.\nUnlike batch builds, where CodeBuild aggregates multiple versions of source code and builds them in the same build container. And for this lab, batch builds aren\u0026rsquo;t necessary.\nFor the Deploy stage Opt for deployment to S3. The S3 Region is in N. Virginia. Select the workshop-01-react bucket created in step 2.4 Check the box Extract file before deploy to unzip files into our bucket. Choose Next The subsequent step involves reviewing the process of creating the CodePipeline. Successful Creation of CodePipeline: Upon creating the CodePipeline, it initiates the first pipeline run. After a while, the pipeline runs successfully. "},{"uri":"/5-publicwebsitedistribution/5.1-createhostedzone/","title":"Create hosted zone","tags":[],"description":"","content":"Here, as I own a domain named bibichannel.site with another domain registrar, I will create a hosted zone in Route 53 to manage my subdomain.\nThis subdomain will be used to resolve to the URL resource of the CloudFront distribution.\nAccess the Route 53 Console, select Hosted zones, then click Create hosted zone. In the Domain name field, enter workshop-01.bibichannel.site to create a child domain for bibichannel.site. In the Description, enter The hosted zone used for workshop-01.bibichannel.site domain. Choose Public hosted zone for the Type. After creation, you will see 2 records: NS and SOA. The NS (Name Server) record contains information about AWS name servers routing requests related to this domain. The SOA (Start of Authority) record in AWS Route 53 is an essential DNS resource record containing management information about a specific domain. The SOA record is typically used to identify the primary name server for the domain, as well as other management information such as Zone ID, administrator\u0026rsquo;s email address, etc. Learn more here. Next, we need to create NS records at the domain registrar where we registered the domain to point to AWS\u0026rsquo;s Name Servers. These NS records will determine which server will manage the information for our child domain. And here, it\u0026rsquo;s AWS Route 53. "},{"uri":"/2-prerequiste/2.1-createvpc/","title":"Create VPC","tags":[],"description":"","content":"In this step, we will need to create a VPC with one public/private subnet. This VPC will be used to deploy the development environment for our React Appliaction via the Cloud9 Service.\nThe architecture overview after completing this step will be as follows:\nWe will utilize the VPC and more feature to quickly create the VPC.\nIn the Create VPC interface:\nSelect the VPC and more feature. In the Name tag auto-generation section, check the box and enter: workshop-01. For IPv4 CIDR block, enter 10.10.0.0/16. In the Number of Availability Zones (AZs) section, choose 1. Next, for both Number of public subnets and Number of private subnets, select 1 each. Then, toggle Customize subnets CIDR blocks and reconfigure the CIDR for the 2 subnets: Public subnet: 10.10.1.0/24 Private subnet: 10.10.2.0/24 For NAT gateways select: None Similarly, VPC endpoints, select: None Finally, click Create VPC Why not create the NAT Gateway now? The initial architecture diagram indeed includes a NAT Gateway. However, I will guide you on how to create it in the following section. We will understand the role of NAT in this model.\nTo learn how to manually create a VPC with public/private subnets, you can refer to the lab: Start with amazon VPC\n"},{"uri":"/","title":"Development &amp; Deployment static website to AWS Cloud","tags":[],"description":"","content":"Overview This workshop aims to guide you through the development and automatic deployment of a static website on the AWS cloud utilizing services such as Cloud9, S3, CodePipeline, CloudFront, Route 53, etc.\nNội dung 1. Introduction 2. Preparation 3. Development Environment 4. Creating the CI/CD Pipeline 5. Public webite 6. Cache Invalidation 7. Resource Cleanup "},{"uri":"/1-introduce/","title":"Introduction","tags":[],"description":"","content":"\nCloud Computing is currently emerging as a prevailing trend worldwide. Numerous enterprises are progressively transitioning their infrastructure to the cloud due to its attributes: agility, scalability, cost-saving, and global deployment within minutes.\nTherefore, in this instructional segment, I will guide you through deploying the development process of your React application directly on the AWS cloud utilizing the Cloud9 IDE tool. Following that, we will proceed with setting up CI/CD for our project using the CodePipeline toolkit. Lastly, we will distribute the website content globally through CloudFront and manage our own domain names via Route 53. "},{"uri":"/4-createcicd/4.2-checkresult/","title":"Check the result","tags":[],"description":"","content":"After running a pipeline from CodePipeline that we\u0026rsquo;ve just created, let\u0026rsquo;s proceed to check the returned results.\nBucket Inspection: To begin, we access the S3\nHere, apart from the bucket created in step 2.4\nCodePipeline generates an additional bucket to store artifacts during the pipeline process.\nNavigate to the workshop-01-react bucket. We observe all necessary files within the build directory of our project present in this bucket. At this stage, you can completely make this content public on the internet from S3, and users can access your website. However, it\u0026rsquo;s advisable to utilize additional CDN and Route 53 services to enhance your website\u0026rsquo;s speed, use your own domain, and bolster security.\nAccessing the other bucket, we find two folders created: BuildArtif and SourceArtif, where artifacts (.Zip) from the source stage and build stage in the pipeline are stored. CodeBuild Examination: Accessing the Build project, we observe: -One successful build with build number as 1, Submitter as codepipeline. All phases of the code build are successful. For a deeper understanding of the phases in a code build, you can refer here. CloudWatch Verification: Accessing the CloudWatch console, clicking on Log groups, we find the log group for the CodeBuild service. Each log group contains sets of log streams, where each log stream represents information about a build process of a project.\nClicking on a log stream provides detailed information.\nThis represents the information of a build process from downloading source to pushing artifacts.\n"},{"uri":"/5-publicwebsitedistribution/5.2-createacm/","title":"Create ACM","tags":[],"description":"","content":"Utilizing the AWS Certificate Manager (ACM) facilitates the provisioning, management, and deployment of public and private SSL/TLS certificates for use with AWS services and resources. ACM streamlines the process of purchasing, uploading, and renewing SSL/TLS certificates, saving significant time.\nAccess the ACM console, select Request certificate, and click Next. Request a certificate for the child domain workshop-01.bibichannel.site by entering it in the Fully qualified domain name field. For Validation method, it\u0026rsquo;s advisable to use DNS validation for a quicker validation process. Leave the rest as default. Click Create, and the ACM is created, but its status will be Pending validation. The next step is to create a record for the validation process to succeed. As AWS services are tightly integrated, you simply need to click Create record in Route 53. The record creation interface appears, generating a CNAME record for validation of our domain. Click Create records. Record creation is successful. After creating the record, ACM successfully validates our domain, and now our domain has an SSL/TLS certificate. You can access https://workshop-01.bibichannel.site to view the certificate. "},{"uri":"/6-invalidatecachecloudfront/6.2-createcommit/","title":"Create Commit","tags":[],"description":"","content":"We will edit the project\u0026rsquo;s code, commit to CodeCommit so that our pipeline runs automatically, then it will deploy to the S3 bucket and automatically perform Invalidation Cloudfront to update the latest code content.\nTo speed things up, I\u0026rsquo;ll edit the source code directly in the CodeCommit console. In reality, you should use a proper development environment like Cloud9 for your project development. Edit the code as shown in the image below and commit it. Back in CodeCommit, you\u0026rsquo;ll see that it has detected the changes in our source code, and our pipeline has been triggered. After waiting for a while, our pipeline has run successfully. Select view detail on the InvalidateCloudfront action to see that our API call command has been successful and the Invalidation has been created. Go to the CloudFront console, access Distributions, and select Invalidations. You\u0026rsquo;ll see the information for the created Invalidation. Next, access https://workshop-01.bibichannel.site to check for the changes. Before After "},{"uri":"/3-developmentenvironment/3.2-createelasticip/","title":"Create Elastic IP","tags":[],"description":"","content":"To create a NAT gateway, we need to allocate a public Elastic IP to assign to the NAT gateway.\nAccess EC2\nSelect Elastic IPs. Click on Allocate Elastic IP address. In the Allocate Elastic IP address interface:\nFor Network border group, choose the correct region you are practicing in. Here, I select us-east-1. For Public IPv4 address pool, select Amazon’s pool of IPv4 addresses. Click Allocate Now, you have successfully created an Elastic IP.\n"},{"uri":"/2-prerequiste/2.2-createsg/","title":"Create Security Group","tags":[],"description":"","content":"As we will be creating a Cloud9 no-ingress EC2 instance, we need to create a Security Group for the Session Manager service\u0026rsquo;s endpoint interfaces. These connections will be encrypted via TLS over HTTPS, so we need to create an inbound rule to allow port 443.\nAccess the VPC service management interface: Click on Security Groups. Click on Create security group. In the Create security group interface: In the Security group name field, enter VPC Endpoint. In the Description field, enter Allow traffic to the endpoint.. Under VPC, click and select the VPC you have created for this lab. Configure the inbound rule and outbound rule for the SG as shown below. For the inbound rule with the source CIDR of the VPC, it allows resources within the VPC to send traffic to this security group.\nClick on Create security group "},{"uri":"/2-prerequiste/","title":"Preparation ","tags":[],"description":"","content":"In this section, you will need to create basic services before proceeding to create the development environment for the React app. These services include: VPC, Subnet, Security group, Interface Endpoint, S3, and CodeCommit.\nContent Create VPC Create Security Group Create Interface Enpoint Create S3 bucket Create CodeCommit "},{"uri":"/5-publicwebsitedistribution/5.3-createcloudfront/","title":"Create Cloudfront","tags":[],"description":"","content":"In this step, we\u0026rsquo;ll create a CloudFront distribution to distribute the content of our website.\nAccess the CloudFront console, and for the Origin domain, select the URL of the workshop-01-react S3 bucket. For Origin access identity, select Legacy access identities. You can choose from the list or select Create new OAI. Tick Yes, update the bucket policy under Bucket policy. For Compress objects automatically, select Yes to compress content when sending it to viewers. Viewer protocol policy will be Redirect HTTP to HTTPS. Keep the rest as default. Scroll down to WAF, for this lab, we won\u0026rsquo;t use it. Select Do not enable security protections. We\u0026rsquo;ll limit our content distribution to a few regions instead of global. So for Price class, select Use North America, Europe, Asia, Middle East, and Africa. In Alternate domain name (CNAME), enter your child domain: workshop-01.bibichannel.site. For Custom SSL certificate, choose the ACM certificate we created in step 5.2. In Default root object, enter index.html. Then press Create distribution. Our CloudFront is successfully created with the URL: https://d1y4dlqj807yu9.cloudfront.net. The distribution process will take place within a short time, typically a few minutes. Upon accessing, we see that the website is working. However, when accessing https://workshop-01.bibichannel.site, our website is not available. This is because we missed creating an A record DNS for the child domain pointing to the CloudFront resources URL. The next step is to create the record. "},{"uri":"/2-prerequiste/2.3-createinterface/","title":"Create Interface Enpoint","tags":[],"description":"","content":"To allow other services to connect to EC2 instances located in private subnets via Session Manager, we need to place the System Manager\u0026rsquo;s endpoint within the VPC, meaning using VPC interface endpoints.\nTherefore, in this instructional section, we will create the following 3 interfaces:\nService com.amazonaws..ssm named Ssm Service com.amazonaws..ec2messages named Ec2message Service com.amazonaws..ssmmessages named Ssmmessage To create a VPC Endpoint, we need to enable the DNS hostnames feature on the VPC. Recall that we enabled this feature when creating the VPC initially. You can refer to more details here.\nAccess the VPC service management interface, click on Endpoint, and then click on Create Endpoint.\nOn the Create endpoint page:\nIn the Name tag section, enter Ssm. For Service category, select: AWS services Next, Service Name, enter: ssm then select service name: com.amazonaws.us-east-1.ssm. Under VPC, select workshop-01-vpc. hoose the first AZ and select private subnet Scroll down.\nIn the Security Group section, select the VPC Endpoint security group we previously created. In the Policy section, choose Full access. Continue creating 2 more interface endpoints, and below is the result after completion.\n"},{"uri":"/3-developmentenvironment/3.3-createnatgateway/","title":"Create NAT gateway","tags":[],"description":"","content":"Access the VPC:\nSelect NAT Gateways. Click on Create NAT gateway In the Create NAT gateway interface:\nName it as follows: workshop-01-ngw For Subnet, choose the public subnet. For Connectivity type, select Public. For Elastic IP allocation ID, choose the Elastic IP you just created. Click Create NAT gateway. You have successfully created the NAT gateway.\n"},{"uri":"/3-developmentenvironment/","title":"Development Environment","tags":[],"description":"","content":"In this step, we will utilize the Cloud9 service to deploy our React App.\nAWS Cloud9 is an integrated development environment (IDE) that allows you to write, run, and debug your code in the browser. It includes a code editor, debugger, and command-line interface. Cloud9 comes pre-packaged with necessary tools for popular programming languages such as JavaScript, Python, PHP, etc.\nAdditionally, it allows us to create a Cloud9 no-ingress EC2 instance to enhance security during the web application development process. It involves creating an EC2 instance in a private subnet and using Session Manager to connect from Cloud9 to our EC2 instance, as illustrated in the diagram below:\nCreating an EC2 instance for the Cloud9 service in a private subnet and setting up interface endpoints for SSM is a standard procedure.\nSo why do we need to add a public subnet and a NAT Gateway?\nThis is because when deploying a development environment, you still need to access the internet to download dependencies for your project. Without being linked to a NAT Gateway placed in a public subnet, the private subnet cannot access the internet.\nYou can refer to more details here.\nAccording to the above model, we will go through the following steps in this section to develop our application and manage its source code:\nContent Create Cloud9 Create ElasticIP Create NAT gateway Create Routes cho Route Table Check internet connection Create React App Push code to CodeCommit "},{"uri":"/5-publicwebsitedistribution/5.4-createrecord/","title":"Create Record","tags":[],"description":"","content":" Access Route 53, go to Hosted zones, select workshop-01.bibichannel.site, then press Create record. Choose Record type as A and enable Alias. Select Route traffic to CloudFront. Then choose the URL of the CloudFront distribution we created in step 5.3. Click Create records. Go back to the URL https://workshop-01.bibichannel.site You\u0026rsquo;ll see that our website is now up. This process may take some time, so please be patient. "},{"uri":"/3-developmentenvironment/3.4-createroutes/","title":"Create Routes","tags":[],"description":"","content":"To create a Private Route Table and associate it with private subnets:\nIn the VPC interface:\nSelect Route Tables. Choose the private route table. In the private route table interface:\nSelect Edit routes. In the Edit routes interface:\nAdd a new route with the destination to the internet. To route traffic to the internet, target the NAT gateway with the ID of the NAT gateway you just created. Then, save it. Returning to the private route table interface, you will see that routes for routing traffic to the internet through the NAT gateway have been added.\n"},{"uri":"/2-prerequiste/2.4-creates3/","title":"Create S3 bucket","tags":[],"description":"","content":"In the initial diagram, we also have an S3 Bucket as the storage location for the static website, so let\u0026rsquo;s proceed to create it as it\u0026rsquo;s relatively straightforward.\nIn the Create bucket interface: AWS region: Choose the S3 bucket in the region where we are conducting the lab. Currently, I am doing the lab in the N. Virginia (us-east-1) region. Bucket Type: Within the scope of this lab, we\u0026rsquo;ll choose General purpose. Enter a Bucket name. It must be unique. You can choose any name; here, I\u0026rsquo;ll create a bucket named workshop-01-react. AWS S3 can be publicly accessible, and it provides us with access to its bucket and objects via REST API. Essentially, the path must adhere to DNS and cannot have duplicate domain names. Therefore, bucket names need to be unique to access groups and objects via the REST API endpoint.\nBelow, we will keep the default configuration and click on Create bucket.\nPay attention to the Block all public access section. We will still enable this feature because the content distribution to the public internet will be done through CloudFront, not the S3 bucket.\n"},{"uri":"/4-createcicd/","title":"Setup CI/CD Pipeline","tags":[],"description":"","content":"To deploy a CI/CD Pipeline, AWS provides us with the CodePipeline toolkit to automate the integration between our development and deployment phases.\nCodePipeline is an AWS service that enables us to build continuous and automated deployment processes. With its simple configuration approach, CodePipeline can visually model the necessary steps for compiling, testing, and deploying updates to an application or service.\nBelow is a guide on how to build a CI/CD Pipeline for our React application.\nContent Create CodePipeline Check the result "},{"uri":"/3-developmentenvironment/3.5-checkconnectioninternet/","title":"Check internet connection","tags":[],"description":"","content":"fter successfully enabling internet access for the EC2 instance in the private subnet to connect to the internet, we return to the Cloud9 IDE interface to proceed with the following:\ncurl google.com ping 8.8.8.8 As observed, the EC2 instance has successfully connected to the internet.\n"},{"uri":"/2-prerequiste/2.5-createcodecommit/","title":"Create CodeCommit","tags":[],"description":"","content":"We need a secure place to store our source code every time we develop an application, and along with that, we need to secure our source code.\nWhile GitHub, Bitbucket, GitLab, etc., provide private repository storage options, they often require payment and contractual obligations, and there\u0026rsquo;s no guarantee of server uptime\nIn contrast, AWS provides us with a service called CodeCommit, which offers private repository storage. It integrates well with other AWS services and provides security and access control through IAM.\nAll of these reasons convince us to use CodeCommit. In this section, we will create a repository using CodeCommit.\nFirstly, let\u0026rsquo;s create a CodeCommit repository. Access CodeCommit. Enter the name of the project we want to store: workshop-01-react. PEnter the description: Repository for react application. Click Create. Creating a repository on CodeCommit is quite simple and fast. In just a few steps, we have a private repository for our project.\n"},{"uri":"/5-publicwebsitedistribution/","title":"Public website &amp; distribution","tags":[],"description":"","content":"In this section, we will continue using CloudFront and Route 53 to publish our website to the internet.\nWe could also publish the website directly on S3 without using these two services, but:\nAmazon S3 CloudFront Deploying the website directly on Amazon S3 is a simple and cost-effective way to host static websites. CloudFront provides a caching layer in front of the website, improving access performance by reducing latency and loading content from edge locations close to users. However, it doesn\u0026rsquo;t support features like HTTP/2, TLS termination, or caching at the origin. CloudFront offers higher security through features such as SSL/TLS encryption, access control, and DDoS protection capabilities. Therefore, I see no reason why we shouldn\u0026rsquo;t use CloudFront to speed up the website and enhance its security.\nAnd Route 53 will help us manage our domain, directing the domain to the CloudFront distribution resource URL.\nContent Create Hosted zone Create ACM Create Cloudfront distribution Create record "},{"uri":"/3-developmentenvironment/3.6-createreactapp/","title":"Create React Application","tags":[],"description":"","content":"In this section, we will deploy a simple React application. Cloud9 provides us with all the necessary libraries to do this without requiring any additional installations.\nExecute the following commands to create the project: mkdir my-react-app cd my-react-app npx create-react-app . npm start If you want to view the running app, select Preview, and then choose Preview Running Application. "},{"uri":"/6-invalidatecachecloudfront/","title":"Invadlidate cache Cloudfront","tags":[],"description":"","content":"Upon activating a new pipeline for deployment to the S3 bucket, CloudFront remains unaware of the changes within S3, thus failing to automatically update its cache.\nConsequently, it becomes imperative to disable the cache of CloudFront to facilitate the refreshing of its content. CloudFront offers us the feature of Invalidations, which can be initiated manually or via CLI to invalidate the cache.\nShall we resort to manual intervention for this task?\nSuch an approach seems antiquated, especially within the context of CI/CD. Therefore, in this section, I will elucidate the process for automating this task.\nContent Add Stage in Codepipeline Creating a Code Commit for Result Verification "},{"uri":"/3-developmentenvironment/3.7-pushcode/","title":"Preparing VPC and EC2","tags":[],"description":"","content":"Next, we will push the code to the repository on CodeCommit that we created in step 2.5\nAccess CodeCommit and copy the repository\u0026rsquo;s HTTPS URL. Then, push the code to CodeCommit using the following commands:\ngit remote add origin https://git-codecommit.us-east-1.amazonaws.com/v1/repos/workshop-01-react git add . git commit -m \u0026#34;fist push\u0026#34; git push --set-upstream origin master Accessing CodeCommit, we can see that the source code has been successfully pushed.\n"},{"uri":"/7-cleanup/","title":"Resource Cleanup","tags":[],"description":"","content":"Let us proceed to dismantle the resources in accordance with the following list:\nTerminate Cloud9. Remove the Nat gateway. Release the Elastic IP. Delete the Interface endpoint. Eliminate the VPC. Erase the A record and CNAME record of the Hosted zoned Route 53. Remove the Hosted zoned Route 53. Invalidate CloudFront and then proceed with deletion. Eliminate the NS record from your domain registrar. Delete the Certificates from ACM. Remove CodePipeline. Delete CodeCommit. Eliminate CodeBuild. Empty the objects within the bucket and proceed to delete the S3 bucket. Remove the role and associated policies. "},{"uri":"/categories/","title":"Categories","tags":[],"description":"","content":""},{"uri":"/tags/","title":"Tags","tags":[],"description":"","content":""}]